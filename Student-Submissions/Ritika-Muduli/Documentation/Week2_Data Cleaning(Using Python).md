# Week 2: Data Cleaning using Python
Week 2 was different and more challenging than Week 1. This week, I learned about data cleaning using Python, which was new to me. Unlike Power Queryâ€™s graphical interface, Python needed me to write code, understand syntax, and think more logically. It felt difficult at first. However, this week showed me how powerful and flexible Python is for working with data
## Getting Started with Python Environment
At the beginning of the week, I learned how to download and set up Python on my system. After that, I was introduced to VS Code as the coding environment and Jupyter Notebook for writing and executing Python code step by step.

Working on Jupyter Notebook was a new experience for me. I learned how each cell runs independently, which helped me experiment with code and understand outputs immediately. Initially, even simple things like installing libraries and running the first code felt confusing, but gradually I became more comfortable
## Introduction to Pandas Library
One of the most important learnings of this week was the Pandas library. I learned that Pandas is used for data manipulation and analysis in Python. Writing commands like pd.read_csv() and understanding DataFrames was completely new to me.

At first, even importing Pandas and reading a dataset felt challenging, but with practice, I started understanding how data is stored in rows and columns, similar to Excel but much more powerful.
## Data Cleaning Techniques Learned in Python
### Removing Duplicate Records
I learned how duplicate records can affect analysis and practiced removing duplicate rows using Pandas functions. This helped in maintaining data accuracy and avoiding repeated information.
### Handling Missing (NaN) and Null Values
Understanding NaN and null values was an important learning for me. I learned how to:
* Identify missing values
* Replace missing values with suitable alternatives
* Remove rows or columns where missing data was not useful
This step helped ensure that the dataset was reliable and ready for analysis.
### Replacing Incorrect Values
I worked on replacing incorrect or unwanted values, such as special characters like / or inconsistent entries. This helped in standardizing the data and making it consistent across the dataset.
### Splitting Columns
I learned how to split a single column into multiple columns using Python. This was helpful when one column contained combined information, and splitting it made the data more structured and meaningful.
### Dropping Unnecessary Columns
Similar to Power Query, I also learned how to drop unnecessary columns in Python. Removing such columns helped keep the dataset clean and focused only on relevant information.
## Challenges Faced During Week 2
Since Python was completely new to me, I initially faced difficulty in:
* Remembering syntax
* Understanding errors shown in the notebook
* Writing correct Pandas commands
However, by practicing and running the code step by step in Jupyter Notebook, I slowly gained confidence and clarity.
## Key Learnings from Week 2
* Python allows deeper control over data cleaning compared to other tools.
*
