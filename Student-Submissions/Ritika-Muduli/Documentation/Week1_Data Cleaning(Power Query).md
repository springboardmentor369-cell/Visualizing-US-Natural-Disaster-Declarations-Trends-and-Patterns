# Week 1: Data Cleaning and Transformation using Power Query
Week 1 was my first hands-on experience with the data analytics process. I learned how important data cleaning and transformation are before any kind of analysis. This week mainly focused on using Power Query and understanding how raw data is prepared for meaningful use. The practical learning helped me see that real-world data is rarely perfect and always needs cleaning before I can analyze it
## Introduction to Power Query
Power Query is the tool used in Power BI for cleaning and transforming data. During this week, I learned that Power Query follows the ETL process:
* Extract – bringing data from different sources
* Transform – cleaning, modifying, and structuring the data
* Load – loading the cleaned data into Power BI for analysis
What I found useful about Power Query is that it allows transformations without writing code, which makes it beginner-friendly while still being very powerful.
## Importing and Exploring the Dataset
I learned how to import datasets from sources like Excel and CSV files into Power Query. Once the data is loaded into the Power Query Editor, the first step was to carefully explore the dataset.
This exploration included:
* Checking column names
* Identifying incorrect or inconsistent data types
* Looking for blank or null values
* Understanding what each column represents
------------
We were shared with Customer Call List by our mentor for cleaning and transforming
## Data Cleaning Activities Performed
I learned varied steps to clean the data for making it standardised.
### Removing Unnecessary Columns
While working with the dataset, I noticed that some columns were not useful for analysis. I removed them so the data became more focused and easier to work with.
### Handling Missing Values
I came across several missing and null values in the data. Depending on the situation, I either replaced them with suitable values or removed incomplete rows to avoid wrong results.
### Removing Duplicate Records
I learned how duplicate entries can affect analysis, so I identified and removed duplicate records to keep the data accurate and reliable.
### Renaming Columns
To make the dataset easier to understand, I renamed columns with clear and meaningful names, which also helped later during reporting.
### Correcting Data Types
I realized that correct data types are very important.I converted text fields into numbers where required and fixed date formats to ensure proper calculations.
## Data Transformation Techniques Learned
Further, I learned the tranformation techniques to mend the data for enhncing visualisation.
### Splitting and Merging Columns
I practiced splitting columns that contained combined information and merging columns when needed, which helped in organizing the data better.
### Filtering and Sorting Data
By filtering unnecessary records and sorting the data, I was able to focus only on relevant information and understand patterns more clearly.
### Creating Custom Columns
I also created custom columns using simple formulas to derive new insights from existing data without changing the original dataset
This step helped me decide what changes were required to clean the data properly.
## Key Learnings
* I understood that real-world data is rarely clean and always needs proper cleaning before analysis.
* I learned how important data cleaning and transformation are for accurate results and decision-making.
